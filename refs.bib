@dataset{pan21dataset,
  author       = {FRANCISCO RANGEL and
                  BERTa CHULVI and
                  GRETEL LIZ DE LA PEÑA and
                  ELISABETTA FERSINI and
                  PAOLO ROSSO},
  title        = {Profiling Hate Speech Spreaders on Twitter},
  month        = mar,
  year         = 2021,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.5637013},
  url          = {https://doi.org/10.5281/zenodo.5637013}
}


%%%%%%%%%%%%%% LIBRARIES %%%%%%%%%%%%%%%%%
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@article{textblob,
  title={textblob Documentation},
  author={Loria, Steven},
  journal={Release 0.15},
  volume={2},
  year={2018}
}
@unpublished{spacy,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@software{pytorch_lightning,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = {3},
title = {{PyTorch Lightning}},
url = {https://github.com/PyTorchLightning/pytorch-lightning},
version = {1.4},
year = {2019}
}
@article{gensim,
  title={Gensim--python framework for vector space modelling},
  author={Rehurek, Radim and Sojka, Petr},
  journal={NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic},
  volume={3},
  number={2},
  year={2011}
}
@inproceedings{pandas,
  title={Data structures for statistical computing in python},
  author={McKinney, Wes and others},
  booktitle={Proceedings of the 9th Python in Science Conference},
  volume={445},
  pages={51--56},
  year={2010},
  organization={Austin, TX}
}

%%%%%%%%%%%% INTRO %%%%%%%%%%%%%%
@misc{datareportal_stats, title={Digital Around the World}, url={https://datareportal.com/global-digital-overview}, journal={DataReportal}, year={2022}} 

@misc{techjury, title={How much data is created every day in 2022?}, url={https://techjury.net/blog/how-much-data-is-created-every-day/}, journal={Techjury}, author={Bulao, Jacquelyn}, year={2022}}

@misc{baggs_2021, title={Online hate speech rose 20\% during pandemic: 'we've Normalised it'}, url={https://www.bbc.com/news/newsbeat-59292509}, journal={BBC News}, publisher={BBC}, author={Baggs, Michael}, year={2021}, month={Nov}} 
 
 %%%%%%%%% RELATED WORKS %%%%%%%%%%%%%
@misc{methodsSurvey,
      title={A systematic review of Hate Speech automatic detection using Natural Language Processing}, 
      author={Md Saroar Jahan and Mourad Oussalah},
      year={2021},
      eprint={2106.00742},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ElSherief, title={Peer to Peer Hate: Hate Speech Instigators and Their Targets}, volume={12}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/15038}, abstractNote={ &lt;p&gt; While social media has become an empowering agent to individual voices and freedom of expression, it also facilitates anti-social behaviors including online harassment, cyberbullying, and hate speech. In this paper, we present the first comparative study of hate speech instigators and target users on Twitter. Through a multi-step classification process, we curate a comprehensive hate speech dataset capturing various types of hate. We study the distinctive characteristics of hate instigators and targets in terms of their profile self-presentation, activities, and online visibility. We find that hate instigators target more popular and high profile Twitter users, and that participating in hate speech can result in greater online visibility. We conduct a personality analysis of hate instigators and targets and show that both groups have eccentric personality facets that differ from the general Twitter population. Our results advance the state of the art of understanding online hate speech engagement. &lt;/p&gt; }, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, author={ElSherief, Mai and Nilizadeh, Shirin and Nguyen, Dana and Vigna, Giovanni and Belding, Elizabeth}, year={2018}, month={Jun.} }

@article{DBLP:Chaudhry,
  author    = {Prateek Chaudhry and
               Matthew Lease},
  title     = {You Are What You Tweet: Profiling Users by Past Tweets to Improve
               Hate Speech Detection},
  journal   = {CoRR},
  volume    = {abs/2012.09090},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.09090},
  eprinttype = {arXiv},
  eprint    = {2012.09090},
  timestamp = {Sat, 02 Jan 2021 15:43:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-09090.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{overall_best,
  title={Detection of hate speech spreaders using convolutional neural networks},
  author={Siino, Marco and Di Nuovo, Elisa and Tinnirello, Ilenia and La Cascia, Marco},
  booktitle={CLEF},
  year={2021}
}

@article{english_best,
  title={Detection of Hate Speech Spreaders with BERT},
  author={Dukic, David and Kr{\v{z}}ic, Ana Sovic},
  year={2021}
}


%%%%%%%%%%%% MODELS %%%%%%%%%%%%
@article{svm, author = {Cortes, Corinna and Vapnik, Vladimir}, title = {Support-Vector Networks}, year = {1995}, issue_date = {Sept. 1995}, publisher = {Kluwer Academic Publishers}, address = {USA}, volume = {20}, number = {3}, issn = {0885-6125}, url = {https://doi.org/10.1023/A:1022627411411}, doi = {10.1023/A:1022627411411}, abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.}, journal = {Mach. Learn.}, month = sep, pages = {273–297}, numpages = {25}, keywords = {pattern recognition, neural networks, efficient learning algorithms, radial basis function classifiers, polynomial classifiers} }

@INPROCEEDINGS{rf,
  author={ {Tin Kam Ho}},
  booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition}, 
  title={Random decision forests}, 
  year={1995},
  volume={1},
  number={},
  pages={278-282 vol.1},
  doi={10.1109/ICDAR.1995.598994}}

@inproceedings{xgboost, 
 author = {Chen, Tianqi and Guestrin, Carlos}, 
 title = {{XGBoost}: A Scalable Tree Boosting System}, 
 booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 
 series = {KDD '16}, 
 year = {2016}, 
 isbn = {978-1-4503-4232-2}, 
 location = {San Francisco, California, USA}, 
 pages = {785--794}, 
 numpages = {10}, 
 url = {http://doi.acm.org/10.1145/2939672.2939785}, 
 doi = {10.1145/2939672.2939785}, 
 acmid = {2939785}, 
 publisher = {ACM}, 
 address = {New York, NY, USA}, 
 keywords = {large-scale machine learning}, 
}

@article{lightgbm,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={3146--3154},
  year={2017}
}

@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}
@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@misc{adamw,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}




@misc{bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{albert,
      title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations}, 
      author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
      year={2020},
      eprint={1909.11942},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



%%%%%%%%%% NEW %%%%%%%%%%%%%%%%
%% DATASETS

@InProceedings{zeerak,
  author    = {Waseem, Zeerak  and  Hovy, Dirk},
  title     = {Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter},
  booktitle = {Proceedings of the NAACL Student Research Workshop},
  month     = {June},
  year      = {2016},
  address   = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  pages     = {88--93},
  url       = {http://www.aclweb.org/anthology/N16-2013}
}

@inproceedings{hateval,
    title = "{S}em{E}val-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in {T}witter",
    author = "Basile, Valerio  and
      Bosco, Cristina  and
      Fersini, Elisabetta  and
      Nozza, Debora  and
      Patti, Viviana  and
      Rangel Pardo, Francisco Manuel  and
      Rosso, Paolo  and
      Sanguinetti, Manuela",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2007",
    doi = "10.18653/v1/S19-2007",
    pages = "54--63",
    abstract = "The paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks.",
}

%% MODELS
@misc{roberta-finetuned,
  doi = {10.48550/ARXIV.2010.12421},
  
  url = {https://arxiv.org/abs/2010.12421},
  
  author = {Barbieri, Francesco and Camacho-Collados, Jose and Neves, Leonardo and Espinosa-Anke, Luis},
  
  keywords = {Computation and Language (cs.CL), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{attention,
  doi = {10.48550/ARXIV.1706.03762},
  
  url = {https://arxiv.org/abs/1706.03762},
  
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Attention Is All You Need},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{fermi,
    title = "{FERMI} at {S}em{E}val-2019 Task 5: Using Sentence embeddings to Identify Hate Speech Against Immigrants and Women in {T}witter",
    author = "Indurthi, Vijayasaradhi  and
      Syed, Bakhtiyar  and
      Shrivastava, Manish  and
      Chakravartula, Nikhil  and
      Gupta, Manish  and
      Varma, Vasudeva",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2009",
    doi = "10.18653/v1/S19-2009",
    pages = "70--74",
    abstract = "This paper describes our system (Fermi) for Task 5 of SemEval-2019: HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter. We participated in the subtask A for English and ranked first in the evaluation on the test set. We evaluate the quality of multiple sentence embeddings and explore multiple training models to evaluate the performance of simple yet effective embedding-ML combination algorithms. Our team - Fermi{'}s model achieved an accuracy of 65.00{\%} for English language in task A. Our models, which use pretrained Universal Encoder sentence embeddings for transforming the input and SVM (with RBF kernel) for classification, scored first position (among 68) in the leaderboard on the test set for Subtask A in English language. In this paper we provide a detailed description of the approach, as well as the results obtained in the task.",
}


%% libs
@article{imbalanced-learn,
author  = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
title   = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
journal = {Journal of Machine Learning Research},
year    = {2017},
volume  = {18},
number  = {17},
pages   = {1-5},
url     = {http://jmlr.org/papers/v18/16-365.html}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@inproceedings{sentiwordnet,
    title = "{S}enti{W}ord{N}et 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining",
    author = "Baccianella, Stefano  and
      Esuli, Andrea  and
      Sebastiani, Fabrizio",
    booktitle = "Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)",
    month = may,
    year = "2010",
    address = "Valletta, Malta",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2010/pdf/769_Paper.pdf",
    abstract = "In this work we present SENTIWORDNET 3.0, a lexical resource explicitly devised for supporting sentiment classification and opinion mining applications. SENTIWORDNET 3.0 is an improved version of SENTIWORDNET 1.0, a lexical resource publicly available for research purposes, now currently licensed to more than 300 research groups and used in a variety of research projects worldwide. Both SENTIWORDNET 1.0 and 3.0 are the result of automatically annotating all WORDNET synsets according to their degrees of positivity, negativity, and neutrality. SENTIWORDNET 1.0 and 3.0 differ (a) in the versions of WORDNET which they annotate (WORDNET 2.0 and 3.0, respectively), (b) in the algorithm used for automatically annotating WORDNET, which now includes (additionally to the previous semi-supervised learning step) a random-walk step for refining the scores. We here discuss SENTIWORDNET 3.0, especially focussing on the improvements concerning aspect (b) that it embodies with respect to version 1.0. We also report the results of evaluating SENTIWORDNET 3.0 against a fragment of WORDNET 3.0 manually annotated for positivity, negativity, and neutrality; these results indicate accuracy improvements of about 20{\%} with respect to SENTIWORDNET 1.0.",
}